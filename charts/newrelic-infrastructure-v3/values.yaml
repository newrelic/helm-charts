# nameOverride: ""
# fullnameOverride: ""

# -- Images used by the chart for the integration and agents.
# @default -- See `values.yaml`
images:
  pullSecrets: []
  # Image for the New Relic Infrastructure Agent sidecar.
  forwarder:
    pullPolicy: IfNotPresent
    # -- Tag for the agent sidecar.
    tag: 1.20.5
    # -- Image for the agent sidecar.
    repository: newrelic/k8s-events-forwarder
    registry: docker.io
  # Image for the New Relic Infrastructure Agent plus integrations.
  agent:
    pullPolicy: IfNotPresent
    # -- Tag for the agent and integrations bundle.
    tag: 2.7.6
    # -- Image for the agent and integrations bundle.
    repository: newrelic/infrastructure-bundle
    registry: docker.io
  # Image for the New Relic Kubernetes integration.
  integration:
    pullPolicy: IfNotPresent
    # -- Tag for the kubernetes integration.
    tag: 0.1.2
    # -- Image for the kubernetes integration.
    repository: newrelic/nri-kubernetes
    registry: docker.io

# -- Common holds config that applies to all instances of the integration.
# @default -- See `values.yaml`
common:
  # Common.config holds configuration entries that apply to all instances of the integration: kubelet, ksm and control plane.
  config:
    # -- How often the integration should collect and report data.
    interval: 15s
    # Timeout for the different APIs contacted by the integration: Kubernetes, KSM, Kubelet, etc.
    timeout: 30s
  # -- Config for the Infrastructure agent.
  # Will be used by the forwarder sidecars and the agent running integrations.
  # See: https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/
  agentConfig: {}

# -- Configuration for the DaemonSet that collects metrics from the Kubelet
# @default -- See `values.yaml`
kubelet:
  # -- Enable kubelet monitoring.
  # Advanced users only. Setting this to `false` is not supported and will break the New Relic experience.
  enabled: true
  annotations: {}
  tolerations:
    - operator: "Exists"
      effect: "NoSchedule"
    - operator: "Exists"
      effect: "NoExecute"
  nodeSelector: {}
  affinity:
    nodeAffinity: {}
  # Extra env ‘items’ that will be added to the definition of the containers; a string is expected (can be templated).
  # extraEnv:
  #  - name: ENV_VAR1
  #    value: "var1"
  #  - name: ENV_VAR2
  #    value: "var2"
  extraEnv: []
  # Extra envFrom ‘items’ that will be added to the definition of the containers; a string is expected (can be templated).
  # extraEnvFrom:
  #  - configMapRef:
  #      name: 'another-config-map'
  extraEnvFrom: []
  # Mount additional volumes into the pod.
  extraVolumes: []
  # Mount additional volume Mounts into the pod.
  extraVolumeMounts: []
  resources:
    limits:
      memory: 300M
    requests:
      cpu: 100m
      memory: 150M
  config: {}

# -- Configuration for the Deployment that collects state metrics from KSM (kube-state-metrics).
# @default -- See `values.yaml`
ksm:
  # -- Enable cluster state monitoring.
  # Advanced users only. Setting this to `false` is not supported and will break the New Relic experience.
  enabled: true
  annotations: {}
  tolerations:
    - operator: "Exists"
      effect: "NoSchedule"
    - operator: "Exists"
      effect: "NoExecute"
  nodeSelector: {}
  affinity:
    podAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            topologyKey: kubernetes.io/hostname
            labelSelector:
              matchLabels:
                app.kubernetes.io/name: kube-state-metrics
          weight: 100
    nodeAffinity: {}
  # Extra env ‘items’ that will be added to the definition of the containers; a string is expected (can be templated).
  # extraEnv:
  #  - name: ENV_VAR1
  #    value: "var1"
  #  - name: ENV_VAR2
  #    value: "var2"
  extraEnv: []
  # Extra envFrom ‘items’ that will be added to the definition of the containers; a string is expected (can be templated).
  # extraEnvFrom:
  #  - configMapRef:
  #      name: 'another-config-map'
  extraEnvFrom: []
  # Mount additional volumes into the pod.
  extraVolumes: []
  # Mount additional volume Mounts into the pod.
  extraVolumeMounts: []
  resources:
    limits:
      memory: 300M
    requests:
      cpu: 100m
      memory: 150M
  config: {}

# -- Configuration for the DaemonSet that collects metrics from the control plane.
# @default -- See `values.yaml`
controlPlane:
  # -- Enable control plane monitoring. Requires `privileged` mode to be enabled.
  enabled: true
  annotations: {}
  tolerations:
    - operator: "Exists"
      effect: "NoSchedule"
    - operator: "Exists"
      effect: "NoExecute"
  nodeSelector: {}
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: node-role.kubernetes.io/control-plane
                operator: Exists
          - matchExpressions:
              - key: node-role.kubernetes.io/controlplane
                operator: Exists
          - matchExpressions:
              - key: node-role.kubernetes.io/etcd
                operator: Exists
          - matchExpressions:
              - key: node-role.kubernetes.io/master
                operator: Exists
  # -- How to deploy the control plane scraper. If autodiscovery is in use, it should be `DaemonSet`.
  # Advanced users using static endpoints should be `Deployment` to avoid reporting metrics twice.
  kind: DaemonSet
  # Extra env ‘items’ that will be added to the definition of the containers; a string is expected (can be templated).
  # extraEnv:
  #  - name: ENV_VAR1
  #    value: "var1"
  #  - name: ENV_VAR2
  #    value: "var2"
  extraEnv: []
  # Extra envFrom ‘items’ that will be added to the definition of the containers; a string is expected (can be templated).
  # extraEnvFrom:
  #  - configMapRef:
  #      name: 'another-config-map'
  extraEnvFrom: []
  # Mount additional volumes into the pod.
  extraVolumes: []
  # Mount additional volume Mounts into the pod.
  extraVolumeMounts: []
  resources:
    limits:
      memory: 300M
    requests:
      cpu: 100m
      memory: 150M
  config:
    # ETCD monitoring configuration
    etcd:
      # -- Enable etcd monitoring. Might require manual configuration in some environments.
      enabled: true
      # Discover etcd pods using the following namespaces and selectors.
      autodiscover:
        - selector: "tier=control-plane,component=etcd"
          namespace: kube-system
          # Only attempt to match the endpoints below in nodes that contain at least one pod matching the selector above:
          matchNode: true
          # Try to reach etcd using the following endpoints.
          endpoints:
            - url: https://localhost:4001
              insecureSkipVerify: true
              auth:
                type: bearer
            - url: http://localhost:2381
        - selector: "k8s-app=etcd-manager-main"
          namespace: kube-system
          matchNode: true
          endpoints:
            - url: https://localhost:4001
              insecureSkipVerify: true
              auth:
                type: bearer
        - selector: "k8s-app=etcd"
          namespace: kube-system
          matchNode: true
          endpoints:
            - url: https://localhost:4001
              insecureSkipVerify: true
              auth:
                type: bearer
      ## OpenShift
      # - selector: "k8s-app=etcd"
      #   namespace: kube-system
      #   matchNode: true
      #   endpoints:
      #     - url: https://localhost:9979
      #       insecureSkipVerify: true
      #       auth:
      #         type: mTLS
      #         mtls:
      #           secretName: secret-name
      #           secretNamespace: secret-namespace
    # Scheduler monitoring configuration
    scheduler:
      # -- Enable scheduler monitoring.
      enabled: true
      autodiscover:
        - selector: "tier=control-plane,component=kube-scheduler"
          namespace: kube-system
          matchNode: true
          endpoints:
            - url: https://localhost:10259
              insecureSkipVerify: true
              auth:
                type: bearer
        - selector: "k8s-app=kube-scheduler"
          namespace: kube-system
          matchNode: true
          endpoints:
            - url: https://localhost:10259
              insecureSkipVerify: true
              auth:
                type: bearer
        - selector: "app=openshift-kube-scheduler,scheduler=true"
          namespace: kube-system
          matchNode: true
          endpoints:
            - url: https://localhost:10259
              insecureSkipVerify: true
              auth:
                type: bearer
    # Controller manager monitoring configuration
    controllerManager:
      # -- Enable controller manager monitoring.
      enabled: true
      autodiscover:
        - selector: "tier=control-plane,component=kube-controller-manager"
          namespace: kube-system
          matchNode: true
          endpoints:
            - url: https://localhost:10257
              insecureSkipVerify: true
              auth:
                type: bearer
        - selector: "k8s-app=kube-controller-manager"
          namespace: kube-system
          matchNode: true
          endpoints:
            - url: https://localhost:10257
              insecureSkipVerify: true
              auth:
                type: bearer
        - selector: "app=kube-controller-manager,kube-controller-manager=true"
          namespace: kube-system
          matchNode: true
          endpoints:
            - url: https://localhost:10257
              insecureSkipVerify: true
              auth:
                type: bearer
             #  mtls:
             #    secretName: secret-name
             #    secretNamespace: secret-namespace
        - selector: "app=controller-manager,controller-manager=true"
          namespace: kube-system
          matchNode: true
          endpoints:
            - url: https://localhost:10257
              insecureSkipVerify: true
              auth:
                type: bearer
    # API Server monitoring configuration
    apiServer:
      # -- Enable API Server monitoring
      enabled: true
      autodiscover:
        - selector: "tier=control-plane,component=kube-apiserver"
          namespace: kube-system
          matchNode: true
          endpoints:
            - url: https://localhost:8443
              insecureSkipVerify: true
              auth:
                type: bearer
            - url: http://localhost:8080
        - selector: "k8s-app=kube-apiserver"
          namespace: kube-system
          matchNode: true
          endpoints:
            - url: https://localhost:8443
              insecureSkipVerify: true
              auth:
                type: bearer
            - url: http://localhost:8080
        - selector: "app=openshift-kube-apiserver,apiserver=true"
          namespace: kube-system
          matchNode: true
          endpoints:
            - url: https://localhost:8443
              insecureSkipVerify: true
              auth:
                type: bearer

# -- Update strategy for the DaemonSets deployed.
# @default -- See `values.yaml`
updateStrategy:
  type: RollingUpdate
  rollingUpdate:
    maxUnavailable: 1

# -- Custom attributes to be added to the data reported by all integrations reporting in the cluster.
customAttributes: {}

# -- Enable verbose logging for all components.
verboseLog: false

# -- Settings controlling ServiceAccount creation.
# @default -- See `values.yaml`
serviceAccount:
  # -- Whether the chart should automatically create the ServiceAccount objects required to run.
  create: true
  annotations: {}
  # If not set and create is true, a name is generated using the fullname template
  name: ""

# -- Annotations to be added to all pods created by the integration.
podAnnotations: {}
# -- Labels to be added to all pods created by the integration.
podLabels: {}

# -- Pod scheduling priority
# Ref: https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/
priorityClassName: ""

# -- Security context used in all the containers of the pods
# When `privileged == true`, the Kubelet scraper will run as root and ignore these settings.
# @default -- See `values.yaml`
securityContext:
  # OpenShift users might want to change the default UID:GID to be inside the allowed range.
  runAsUser: 1000
  runAsGroup: 2000
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: true

# -- Run the integration with full access to the host filesystem and network.
# Running in this mode allows reporting fine-grained cpu, memory, process and network metrics for your nodes.
# Additionally, it allows control plane monitoring, which requires hostNetwork to work.
privileged: true

# -- Settings controlling RBAC objects creation.
rbac:
  # -- Whether the chart should automatically create the RBAC objects required to run.
  create: true
  # -- Whether the chart should create Pod Security Policy objects.
  pspEnabled: false

# -- Config files for other New Relic integrations that should run in this cluster.
integrations: {}
# If you wish to monitor services running on Kubernetes you can provide integrations
# configuration under `integrations`. You just need to create a new entry where
# the key is the filename of the configuration file and the value is the content of
# the integration configuration. The key must end in ".yaml" as this will be the
# filename generated and the Infrastructure agent only looks for YAML files.
# The data is the actual integration configuration as described in the spec here:
# https://docs.newrelic.com/docs/integrations/integrations-sdk/file-specifications/integration-configuration-file-specifications-agent-v180
# For example, if you wanted to monitor a Redis instance that has a label "app=sampleapp"
# you could do so by adding following entry:
#  nri-redis-sampleapp:
#    discovery:
#      command:
#        # Run NRI Discovery for Kubernetes
#        # https://github.com/newrelic/nri-discovery-kubernetes
#        exec: /var/db/newrelic-infra/nri-discovery-kubernetes
#        match:
#          label.app: sampleapp
#    integrations:
#      - name: nri-redis
#        env:
#          # using the discovered IP as the hostname address
#          HOSTNAME: ${discovery.ip}
#          PORT: 6379
#        labels:
#          env: test

# Collect detailed metrics from processes running in the host.
# @default -- [True only for accounts created before July 20, 2020.](https://docs.newrelic.com/docs/release-notes/infrastructure-release-notes/infrastructure-agent-release-notes/new-relic-infrastructure-agent-1120)
# enableProcessMetrics: false

# Send data to New Relic Staging. Requires an staging-specific License Key.
# nrStaging: false

# Prefix nodes display name with cluster to reduce chances of collisions
# prefixDisplayNameWithCluster: false

# 'true' will use the node name as the name for the "host",
#  note that it may cause data collision if the node name is the same in different clusters
#  and prefixDisplayNameWithCluster is not set to true.
# 'false' will use the host name as the name for the "host".
# useNodeNameAsDisplayName: true
