Your deployment of the New Relic Infrastructure agent is complete if you have not used --wait during the installation of this helm chart. You can check on the progress of this by running the following command:

    kubectl get daemonset -o wide -w --namespace {{ .Release.Namespace }} {{ template "newrelic.fullname" . }}

{{- if and (include "newrelic.fargate" .) .Values.kubelet.affinity.nodeAffinity }}

###########
# WARNING #
###########

You have specified both an EKS Fargate environment (global.fargate) and custom
nodeAffinity rules, so we couldn't automatically exclude the kubelet daemonSet from
Fargate nodes. In order for the integration to work, you MUST manually exclude
the daemonSet from Fargate nodes.

Please make sure your custom .Values.kubelet.affinity.nodeAffinity achieve the same effect as:

affinity:
  nodeAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
        - matchExpressions:
            - key: eks.amazonaws.com/compute-type
              operator: NotIn
              values:
                - fargate
{{- end }}

{{- if or (not .Values.ksm.enabled) (not .Values.kubelet.enabled) }}

###########
# WARNING #
###########

You have specified ksm or kubelet integration components as not enabled.
Those components are needed to have the full experience on NROne kubernetes explorer.

{{- end }}

{{- if and .Values.nodeAffinity .Values.controlPlane.enabled (not (include "newrelic.fargate" .)) }}

-> WARNING LEGACY CONFIG <-
    You have specified the legacy "nodeAffinity" option into values, however the new version of the chart
    supports a different nodeAffinity options per component.

    The value specified has been applied automatically to ksm and kubelet workloads, however **NOT** to the control plane one.

    Keep in mind you should leverage the new ksm.affinity.nodeAffinity, controlPlane.affinity.nodeAffinity
    and kubelet.affinity.nodeAffinity to customize nodeAffinity.
{{- end }}

{{- if .Values.resources }}

-> WARNING LEGACY CONFIG <-
    You have specified the legacy "resources" option into values, however the new version of the chart
    supports different resources per component, therefore the value specified has been ignored.

    Please use ksm.resources, controlPlane.resources and kubelet.resources.
{{- end }}

{{- if .Values.tolerations }}

-> WARNING LEGACY CONFIG <-
    You have specified the legacy "tolerations" options into values, however the new version of the chart
    supports different tolerations per component, therefore the value specified has been ignored.
    Please use ksm.tolerations, controlPlane.tolerations and kubelet.tolerations.
{{- end }}

{{- if .Values.logFile }}

-> WARNING LEGACY CONFIG <-
    The "logFile" value is no longer supported, please specify the option "log_file" directly in "common.agentConfig".
    Notice that you will need as well to set securityContext.readOnlyRootFilesystem to false or add extraVolumes to allow
    the container to write to such location
{{- end }}

{{ $errors:= "" }}

{{- if .Values.image }}
{{ $errors = printf "%s%s" $errors (include "newrelic.compatibility.message.image" . | nindent 2) }}
{{- end }}

{{- if (or .Values.enableWindows .Values.windowsOsList .Values.windowsSecurityContext .Values.windowsNodeSelector)}}
{{ $errors = printf "%s%s" $errors (include "newrelic.compatibility.message.windows" . | nindent 2) }}
{{- end }}

{{- if ( or .Values.controllerManagerEndpointUrl  .Values.schedulerEndpointUrl .Values.etcdEndpointUrl .Values.apiServerEndpointUrl )}}
{{ $errors = printf "%s%s" $errors (include "newrelic.compatibility.message.apiURL" . | nindent 2) }}
{{- end }}

{{- if ( or .Values.etcdTlsSecretName .Values.etcdTlsSecretNamespace )}}
{{ $errors = printf "%s%s" $errors (include "newrelic.compatibility.message.etcdSecrets" . | nindent 2) }}
{{- end }}

{{- if .Values.apiServerSecurePort }}
{{ $errors = printf "%s%s" $errors (include "newrelic.compatibility.message.apiServerSecurePort" . | nindent 2) }}
{{- end }}

{{- if $errors }}
{{- fail $errors }}
{{- end }}

